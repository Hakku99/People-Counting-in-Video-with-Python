{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8o9sn3zjP2Rz"
   },
   "source": [
    "# Import Libraries and Reading the Input Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gZnCJiDyP2R2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "# Reading video file from folder, video need to put in same folder with code\n",
    "cap = cv2.VideoCapture('IMG_8096.MOV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiMmr49-P2R_"
   },
   "source": [
    "# Apply all the necessary techniques to detect the people in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhsDRTPEP2SB"
   },
   "outputs": [],
   "source": [
    "ret,frame1=cap.read()\n",
    "ret,frame2=cap.read()\n",
    "while cap.isOpened():\n",
    "    # If video is not finished, then proceed\n",
    "    if ret:\n",
    "        # Resize the previous frame and the current frame into the width of 600\n",
    "        frame1 = imutils.resize(frame1, width=600)\n",
    "        frame2 = imutils.resize(frame2, width=600)\n",
    "        # Apply Image Differences to find the differences between previous and current frame\n",
    "        diff=cv2.absdiff(frame1,frame2)\n",
    "        # Convert the frame into grayscale\n",
    "        gray=cv2.cvtColor(diff,cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Bilateral Filter to remove the noise\n",
    "        blurred = cv2.bilateralFilter(gray,10,40,40)\n",
    "        # Apply Canny Edge Detector to obtain the all the edges\n",
    "        edged = cv2.Canny(blurred,30,200)\n",
    "        # Apply Adaptive Thresholding to segment the frames\n",
    "        thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        # Apply Bitwise Not to obtain the mask of the frame\n",
    "        mask = cv2.bitwise_not(edged)\n",
    "        # Apply Bitwise And to get the sharpen edges of the frame\n",
    "        thresh = cv2.bitwise_and(thresh,thresh,mask=mask)\n",
    "        # Apply Opening to open the connections of the people detected in the frame\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(37,37))\n",
    "        thresh = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel)\n",
    "        # Apply Bitwise Not again to convert all the background frames and people detected from white to black and black to white respectively\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "        # Display the result of the thresholded video in black and white\n",
    "        cv2.imshow(\"Frame1\",thresh)\n",
    "        # Find Contours in the thresholded frame\n",
    "        contours,_=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Initialize counter into zero\n",
    "        count=0\n",
    "        for contour in contours:\n",
    "            # Save all the coordinates\n",
    "            (x,y,w,h)=cv2.boundingRect(contour)\n",
    "            # if the area of contour is less than 5000, do nothing\n",
    "            if cv2.contourArea(contour)<5000:\n",
    "                continue\n",
    "            # If the people are detected in the frame, the counter is increased by 1\n",
    "            count=count+1\n",
    "            # Draw the rectangle bounding box for each people detected in the frame\n",
    "            cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            # Display text about the total number of people detected in the lower left corner\n",
    "            cv2.putText(frame1,\"{} people is approaching you\".format(str(count)),(10,325),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "       # Display the output video for the user\n",
    "        cv2.imshow(\"feed\",frame1)\n",
    "        frame1=frame2\n",
    "        ret,frame2=cap.read()\n",
    "        # Press 'Q' if want to terminate the program before video end\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # if video finished, then break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Finalized Q1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
